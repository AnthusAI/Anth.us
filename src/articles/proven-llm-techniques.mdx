---
title: "Proven LLM Techniques"
slug: "proven-llm-techniques"
date: "2023-12-14"
excerpt: Tried and true methods of getting the best results from large language models
authors:
  - author: <a href="/ryan">Ryan Porter</a>
  - author: and the <a href="https://chat.openai.com/g/g-MA4ZbLQBi-assistant-alpha"><i>Anthus</i></a> GPT
tags: []
preview_image: "./images/draft-1.png"
images:
  - ./images/draft-1.png
state: draft
---

import ArticleImage from '../components/article-image';
import { Citation, CitationsList } from 'gatsby-citation-manager';

We now have citations showing independent, quantified confirmations of all the basic, underlying design principles in the Plexus agentic scores.
* Task decomposition works.
* Shorter prompts work better even if longer prompts would fit in the context window.
* Formatting instructions in the prompt will lower accuracy.
* Chain-of-Thought prompting improves accuracy, with the answer last in the completion.

## Formatting instructions impair accuracy:
https://arxiv.org/abs/2408.02442